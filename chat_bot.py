import pandas as pd
import streamlit as st
import requests
from streamlit_searchbox import st_searchbox

# === App Title ===
st.title("üìû Call Center Chatbot")

# === GitHub Repo Info ===
GITHUB_USER = "mintus2511"
GITHUB_REPO = "CC_Chatbot"
GITHUB_API_URL = f"https://api.github.com/repos/{GITHUB_USER}/{GITHUB_REPO}/contents/"

# === Step 1: Get CSV files from GitHub ===
@st.cache_data(ttl=60)
def get_csv_file_links():
    try:
        response = requests.get(GITHUB_API_URL)
        response.raise_for_status()
        files = response.json()

        # Sort filenames so newer ones (e.g., with versioning) come last
        sorted_csvs = sorted(
            [file for file in files if file["name"].endswith(".csv")],
            key=lambda x: x["name"]
        )

        return {
            file["name"]: file["download_url"]
            for file in sorted_csvs
        }
    except Exception as e:
        st.error(f"‚ùå L·ªói khi k·∫øt n·ªëi t·ªõi GitHub: {e}")
        return {}

# === Step 2: Load & clean CSVs ===
@st.cache_data(ttl=60)
def load_csvs(csv_files):
    combined = pd.DataFrame(columns=["key word", "description", "topic"])

    for name, url in csv_files.items():
        try:
            df = pd.read_csv(url)
            df.columns = df.columns.str.lower().str.strip()
            if {"key word", "description"}.issubset(df.columns):
                df["topic"] = name.replace(".csv", "")
                combined = pd.concat([combined, df[["key word", "description", "topic"]]], ignore_index=True)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói ƒë·ªçc {name}: {e}")

    # ‚úÖ Keep only the latest version of each "key word"
    combined = combined.drop_duplicates(subset="key word", keep="last")

    # ‚úÖ Log & remove duplicate descriptions (optional clean-up)
    dupes = combined[combined.duplicated("description", keep=False)].copy()
    removed_duplicates = dupes[dupes.duplicated("description", keep="first")]
    cleaned_data = combined.drop_duplicates(subset="description", keep="first")

    return cleaned_data, removed_duplicates

# === Step 3: Load data ===
csv_files = get_csv_file_links()
data, removed_duplicates = load_csvs(csv_files)

# === Step 4: Chatbot UI ===
if not data.empty:
    all_keywords = sorted(data["key word"].dropna().astype(str).unique())

    def search_fn(user_input):
        return [kw for kw in all_keywords if user_input.lower() in kw.lower()]

    # === Custom CSS to make search box outline only ===
    st.markdown("""
        <style>
        .searchbox-container input {
            background-color: transparent !important;
            border: 2px solid #ccc !important;
            border-radius: 5px;
            padding: 8px;
            color: black;
        }
        .searchbox-container input:focus {
            border-color: #1a73e8 !important;
            outline: none !important;
            box-shadow: none !important;
        }
        </style>
    """, unsafe_allow_html=True)

    with st.container():
        st.markdown('<div class="searchbox-container">', unsafe_allow_html=True)
        selected_keyword = st_searchbox(
            search_fn,
            key="keyword_search",
            label="üîç G√µ t·ª´ kh√≥a",
            placeholder="V√≠ d·ª•: h·ªçc b·ªïng, h·ªçc ph√≠..."
        )
        st.markdown('</div>', unsafe_allow_html=True)

    if selected_keyword:
        st.session_state["selected_keyword"] = selected_keyword

    if "selected_keyword" in st.session_state:
        keyword = st.session_state["selected_keyword"]
        matches = data[data["key word"].str.lower().str.contains(keyword.lower(), na=False)]

        if not matches.empty:
            for _, row in matches.iterrows():
                st.write("ü§ñ **Bot:**", row["description"])
                # st.caption(f"(üìÇ Ch·ªß ƒë·ªÅ: `{row['topic']}` | üîë T·ª´ kh√≥a: `{row['key word']}`)")
        else:
            st.info("Kh√¥ng t√¨m th·∫•y m√¥ t·∫£ cho t·ª´ kh√≥a n√†y.")
else:
    st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h·ª£p l·ªá.")

# === (Optional) Dev View: See removed duplicates ===
# with st.expander("üõ†Ô∏è [Dev] Xem c√°c m√¥ t·∫£ tr√πng l·∫∑p ƒë√£ b·ªã x√≥a", expanded=False):
#     if not removed_duplicates.empty:
#         st.dataframe(removed_duplicates)
#     else:
#         st.write("‚úÖ Kh√¥ng c√≥ m√¥ t·∫£ n√†o b·ªã tr√πng l·∫∑p.")
