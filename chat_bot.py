import pandas as pd
import streamlit as st
import requests
from streamlit_searchbox import st_searchbox

# === Streamlit Title ===
st.title("üìû Call Center Chatbot")

# === GitHub Setup ===
GITHUB_USER = "mintus2511"
GITHUB_REPO = "CC_Chatbot"
GITHUB_API_URL = f"https://api.github.com/repos/{GITHUB_USER}/{GITHUB_REPO}/contents/"

@st.cache_data(ttl=60)
def get_csv_file_links():
    try:
        response = requests.get(GITHUB_API_URL)
        response.raise_for_status()
        files = response.json()
        return {
            file["name"]: file["download_url"]
            for file in files if file["name"].endswith(".csv")
        }
    except Exception as e:
        st.error(f"‚ùå L·ªói khi k·∫øt n·ªëi t·ªõi GitHub: {e}")
        return {}

@st.cache_data(ttl=60)
def load_csvs(csv_files):
    combined = pd.DataFrame(columns=["key word", "description", "topic"])
    for name, url in csv_files.items():
        try:
            df = pd.read_csv(url)
            df.columns = df.columns.str.lower().str.strip()
            if {"key word", "description"}.issubset(df.columns):
                df["topic"] = name.replace(".csv", "")
                combined = pd.concat([combined, df[["key word", "description", "topic"]]], ignore_index=True)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói ƒë·ªçc {name}: {e}")
    return combined

# === Load Data ===
csv_files = get_csv_file_links()
data = load_csvs(csv_files)

# === Check for duplicate descriptions across all CSVs
dupes = data[data.duplicated("description", keep=False)].sort_values("description")

# ‚úÖ Show warning ONLY if there are actual duplicates
if not dupes.empty:
    st.warning(f"üö® C√≥ {dupes['description'].nunique()} m√¥ t·∫£ b·ªã tr√πng l·∫∑p trong c√°c file CSV!")
    with st.expander("üìã Xem m√¥ t·∫£ tr√πng l·∫∑p"):
        st.dataframe(dupes)
    # === Autocomplete Search UI ===
    all_keywords = sorted(data["key word"].dropna().astype(str).unique())

    def search_fn(user_input):
        return [kw for kw in all_keywords if user_input.lower() in kw.lower()]

    selected_keyword = st_searchbox(
        search_fn,
        key="keyword_search",
        label="üîç G√µ t·ª´ kh√≥a",
        placeholder="V√≠ d·ª•: h·ªçc b·ªïng, ch∆∞∆°ng tr√¨nh h·ªçc...",
    )

    # Store selected keyword in session
    if selected_keyword:
        st.session_state["selected_keyword"] = selected_keyword

    # Run search logic only if something was selected
    if "selected_keyword" in st.session_state:
        keyword = st.session_state["selected_keyword"]
        matches = data[data["key word"].str.lower().str.contains(keyword.lower(), na=False)]

        if not matches.empty:
            for _, row in matches.iterrows():
                st.write("ü§ñ **Bot:**", row["description"])
                #st.caption(f"(üìÇ Ch·ªß ƒë·ªÅ: `{row['topic']}` | üîë T·ª´ kh√≥a: `{row['key word']}`)")
        else:
            st.info("Kh√¥ng t√¨m th·∫•y m√¥ t·∫£ cho t·ª´ kh√≥a n√†y.")
else:
    st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h·ª£p l·ªá.")
